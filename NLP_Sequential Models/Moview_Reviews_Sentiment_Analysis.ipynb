{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EdaPtvpaC2d",
        "colab_type": "text"
      },
      "source": [
        "# Predict the sentiments in Movie Reviews datset using RNN\n",
        "- Use Recurrent Neural networks to predict the sentiment of 25000 Movie Reviews. We would like to predict the reviews as positive or negative.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1u1cMYc24S7o",
        "colab_type": "text"
      },
      "source": [
        "### Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV8rXQ8H4N09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "4268a9ef-7c02-4cf1-dd3e-954e9a5f2686"
      },
      "source": [
        "from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "drive.mount('/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-gS_g3AITu9R",
        "colab_type": "text"
      },
      "source": [
        "### Kaggle dataset\n",
        "https://www.kaggle.com/rochachan/bag-of-words-meets-bags-of-popcorn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RL2CqIQJUA9F",
        "colab_type": "text"
      },
      "source": [
        "### Download Kaggle dataset to colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XRrzRcSWT23q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install kaggle support library\n",
        "!pip install kaggle --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXTl-FR3UNsh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make dir for kaggle\n",
        "!mkdir .kaggle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36hzwh_3Xy44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cp '/gdrive/My Drive/AIML/Kaggle_API_Token/kaggle.json' /content/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq1QJXjAVD6e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "37c68b64-2377-466a-85f4-3df2eabc89c3"
      },
      "source": [
        "!ls '/content/.kaggle/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoMZ9PmYXONx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cfd3e0ac-10fa-4f7a-9c14-0449882ea26a"
      },
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp /content/.kaggle/kaggle.json ~/.kaggle/kaggle.json\n",
        "!kaggle config set -n path -v{/content}\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "- path is now set to: {/content}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyOQrDUgZv99",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "77c32ad5-67c9-48f8-e0b1-efe518be12d4"
      },
      "source": [
        "!ls -la /root/.kaggle/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 16\n",
            "drwxr-xr-x 2 root root 4096 Aug  2 11:35 .\n",
            "drwx------ 1 root root 4096 Aug  2 11:35 ..\n",
            "-rw------- 1 root root  101 Aug  2 11:35 kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgZ7_hM9aG-c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "4044079d-03fe-40f9-faad-4c1c1e9da99a"
      },
      "source": [
        "!kaggle datasets list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "ref                                                         title                                             size  lastUpdated          downloadCount  \n",
            "----------------------------------------------------------  -----------------------------------------------  -----  -------------------  -------------  \n",
            "andrewmvd/data-analyst-jobs                                 Data Analyst Jobs                                  2MB  2020-07-14 08:37:57           1714  \n",
            "vzrenggamani/hanacaraka                                     Aksara Jawa / Hanacaraka                           9MB  2020-07-10 15:09:31             59  \n",
            "mrgeislinger/bart-ridership                                 BART Ridership                                   325MB  2020-07-09 22:28:07            179  \n",
            "moezabid/zillow-all-homes-data                              Zillow All Homes Data                              5MB  2020-07-18 11:44:48            732  \n",
            "mrmorj/restaurant-recommendation-challenge                  Restaurant Recommendation Challenge              534MB  2020-07-18 16:25:04            749  \n",
            "vishnuvarthanrao/windows-store                              Windows Store                                     93KB  2020-07-07 12:29:07            978  \n",
            "tanmoyx/covid19-patient-precondition-dataset                COVID-19 patient pre-condition dataset             8MB  2020-07-22 16:37:50           1199  \n",
            "rohanrao/chai-time-data-science                             Chai Time Data Science | CTDS.Show                 3MB  2020-07-23 17:23:46            694  \n",
            "garystafford/environmental-sensor-data-132k                 Environmental Sensor Telemetry Data                7MB  2020-07-20 17:18:10            254  \n",
            "mdabbert/ultimate-ufc-dataset                               Ultimate UFC Dataset                             533KB  2020-08-01 15:52:58            560  \n",
            "benroshan/factors-affecting-campus-placement                Campus Recruitment                                 5KB  2020-04-11 11:09:02          12737  \n",
            "bobbyscience/league-of-legends-diamond-ranked-games-10-min  League of Legends Diamond Ranked Games (10 min)  539KB  2020-04-13 13:53:02           5104  \n",
            "fireballbyedimyrnmom/us-counties-covid-19-dataset           US counties COVID 19 dataset                       4MB  2020-08-01 12:09:13          10876  \n",
            "divyansh22/flight-delay-prediction                          January Flight Delay Prediction                   23MB  2020-04-14 13:15:41           4275  \n",
            "clmentbisaillon/fake-and-real-news-dataset                  Fake and real news dataset                        41MB  2020-03-26 18:51:15          10909  \n",
            "ikiulian/global-hospital-beds-capacity-for-covid19          Global Hospital Beds Capacity (for covid-19)     284KB  2020-04-26 09:39:35           3728  \n",
            "praveengovi/coronahack-chest-xraydataset                    CoronaHack -Chest X-Ray-Dataset                    1GB  2020-03-20 01:26:40           5152  \n",
            "bappekim/air-pollution-in-seoul                             Air Pollution in Seoul                            20MB  2020-04-03 16:33:49           5218  \n",
            "kimjihoo/coronavirusdataset                                 Data Science for COVID-19 (DS4C)                   7MB  2020-07-13 14:07:31          49513  \n",
            "sudalairajkumar/novel-corona-virus-2019-dataset             Novel Corona Virus 2019 Dataset                    2MB  2020-07-30 15:13:56         233402  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vffYPCVYabAT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "1488a468-fc28-40ed-e4d4-366dc888cda2"
      },
      "source": [
        "!kaggle competitions download -c word2vec-nlp-tutorial -p /content"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading sampleSubmission.csv to /content\n",
            "  0% 0.00/276k [00:00<?, ?B/s]\n",
            "100% 276k/276k [00:00<00:00, 52.4MB/s]\n",
            "Downloading unlabeledTrainData.tsv.zip to /content\n",
            " 35% 9.00M/26.0M [00:00<00:00, 34.9MB/s]\n",
            "100% 26.0M/26.0M [00:00<00:00, 65.5MB/s]\n",
            "Downloading testData.tsv.zip to /content\n",
            " 40% 5.00M/12.6M [00:00<00:00, 31.4MB/s]\n",
            "100% 12.6M/12.6M [00:00<00:00, 61.8MB/s]\n",
            "Downloading labeledTrainData.tsv.zip to /content\n",
            " 39% 5.00M/13.0M [00:00<00:00, 43.2MB/s]\n",
            "100% 13.0M/13.0M [00:00<00:00, 63.4MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y0FhzBYcQoa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "b2b129c4-d4cb-4f45-a104-0fd5c442a3fc"
      },
      "source": [
        "!ls -l /content/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 53108\n",
            "-rw-r--r-- 1 root root 13585269 Aug  2 11:36 labeledTrainData.tsv.zip\n",
            "drwxr-xr-x 1 root root     4096 Jul 30 16:30 sample_data\n",
            "-rw-r--r-- 1 root root   282796 Aug  2 11:35 sampleSubmission.csv\n",
            "-rw-r--r-- 1 root root 13258140 Aug  2 11:36 testData.tsv.zip\n",
            "-rw-r--r-- 1 root root 27243285 Aug  2 11:35 unlabeledTrainData.tsv.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PcRIss50fEoS",
        "colab_type": "text"
      },
      "source": [
        "### Load required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiu3ZhhTfSyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hx9w9nz8eZe5",
        "colab_type": "text"
      },
      "source": [
        "# Load trainset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADeYQKE-cxuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('labeledTrainData.tsv.zip', delimiter='\\t', header=0, quoting=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQMuSX11e8Ke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b08084db-615e-4d0f-dbeb-b47ff6402110"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsgpJVY5gtvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "37eebc99-86ff-4721-db1d-808dd0f21c0e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\"5814_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"With all this stuff going down at the moment ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"2381_9\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"\\\"The Classic War of the Worlds\\\" by Timothy ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"7759_3\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"The film starts with a manager (Nicholas Bell...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>\"3630_4\"</td>\n",
              "      <td>0</td>\n",
              "      <td>\"It must be assumed that those who praised thi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"9495_8\"</td>\n",
              "      <td>1</td>\n",
              "      <td>\"Superbly trashy and wondrously unpretentious ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  sentiment                                             review\n",
              "0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n",
              "1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n",
              "2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n",
              "3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n",
              "4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9Os4C4Mh-jt",
        "colab_type": "text"
      },
      "source": [
        "### Split into train and test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mM8URwShCta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKMx0sU9hn8J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "62bc2108-a213-49a7-9fef-8ac6fb50e5ab"
      },
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000,) (20000,)\n",
            "(5000,) (5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daP8ub2wivNB",
        "colab_type": "text"
      },
      "source": [
        "### Build a Tokenizer to Tokenize the text and create word indices\n",
        "- coverting word to numbers \n",
        "1. count vectorization (creates Vocabulary and also assigns indices to the words)\n",
        "2. tf-idf vectorization (creates Vocabulary and also assigns indices to the words)\n",
        "3. wor2vec vectorization (We need to convert the input into one-hot encoding using tokenizer class and the embedding is provided by Neural Network\n",
        "\n",
        "steps:\n",
        "1. Prepare vocabulary of dataset(unique words in the dataset)\n",
        "2. Assisgn index to each of the unique words of Vocabulary\n",
        "3. Use Keras Tokenier class to to create the Vocabularry and assign the indices\n",
        "4. Replace all the words in the reviews with their word indices\n",
        "5. Which means, convert the text in training data(X_train and X_test) by replacing them with the word indices of Vocabulary\n",
        "6. Use text_to_sequences method of tokenizer class to replace each word with its word index\n",
        "7. All examples/text-sequences in a batch should be of same size, because of matrix multiplication requirements. First we should decide the length of input for each batch or the number of words for each review. This can be done using measure like medium of all reviews or mean no of words in all reviews\n",
        "(Here we assume the maximum length of input as 300)\n",
        "8. Pad the sequences which are of length less than the maximum length.Usually padding is done at the beginning of the input (pre)\n",
        "9. Use keras pad_sequences method to pad the sequences having length less than 300 and we use pre padding because LSTM rembembers the latest input well thn the input given in past.So, the beginning zros will be forgotten if pre padding is used\n",
        "10. Next we need to convert the input into one-hot encoding.We will not be doing that, We use Keras to convert the input to one-hot encoding\n",
        "11. After giving the input text in the form of word indices, we need to do two things. Convert the wordIndices into One-hot encoding  and converting it into word2vec embedding.\n",
        "12. The embedding layer in LSTM, takes care of both these steps of converting to one-hot encoding and then convering it into a word2vec embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t6GUpUThvMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKE4CP-upjQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#top_words is the no of words to be considered for creating the Voacbulary .If left empty uses all words in dataset\n",
        "top_words=10000 #Vocabulary size\n",
        "t = tf.keras.preprocessing.text.Tokenizer(num_words= top_words) #num_words-> Vocabulary size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCC0N0SMqeoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Fit tokenizer with actual training data\n",
        "t.fit_on_texts(X_train.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-M3_UgQquTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#word indices\n",
        "#t.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-jZ-gxX0y-1",
        "colab_type": "text"
      },
      "source": [
        "### Prepare Training and Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfge81cAq1jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "28fc86cd-a27c-4d26-d9f3-688d2f962ebe"
      },
      "source": [
        "X_train[0:1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6655    \"Obvious attack on Microsoft made by people wh...\n",
              "Name: review, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EE72f5y7xRV4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#takes each word in text and replaces with its word index\n",
        "X_train = t.texts_to_sequences(X_train.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8__Ki8_kyvwK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X_train[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6-MzGL2yzHQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = t.texts_to_sequences(X_test.tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YORr2NFB173u",
        "colab_type": "text"
      },
      "source": [
        "### How many words should be present in each review?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipnWnuCrzA1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define maximum number of words to consider in each review\n",
        "max_review_length = 300"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU44XV_-2ccc",
        "colab_type": "text"
      },
      "source": [
        "### Pad the Sequences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xcd_bXjZ2N26",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Pad training and test reviews\n",
        "\n",
        "X_train = tf.keras.preprocessing.sequence.pad_sequences(X_train, maxlen=max_review_length, padding='pre')\n",
        "\n",
        "X_test = tf.keras.preprocessing.sequence.pad_sequences(X_test, maxlen=max_review_length, padding='pre')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t84Su3R4I31",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dc2fc029-9be3-4bf1-c3e9-b5cf32e39ae0"
      },
      "source": [
        "print(X_train.shape, X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(20000, 300) (5000, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63j5-9cTCCL2",
        "colab_type": "text"
      },
      "source": [
        "### Build the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrkacjPE6WWx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize a sequential model\n",
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJHik30TDDd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Embedding layer\n",
        "model.add(tf.keras.layers.Embedding(input_dim=top_words+1, \n",
        "                                    output_dim=50, \n",
        "                                    input_length=max_review_length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAIhpvfiGhPN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d7340b6f-fab5-4165-f9a7-535260f4b428"
      },
      "source": [
        "model.output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 300, 50)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbWmMbKQGlOa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "9175fdc2-b799-4703-8629-95ecedae9234"
      },
      "source": [
        "#Add LSTM layer\n",
        "model.add(tf.keras.layers.LSTM(units=256, \n",
        "                               dropout=0.20, \n",
        "                               recurrent_dropout=0.20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZyG9p6J4Iz9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0dcded9f-d768-460b-c48a-d3337e2736a8"
      },
      "source": [
        "model.output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RfJ-dVA1IBMz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Add Dense layer as output layer\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T0PYYlLIwHV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e876c00e-03d3-4a71-9b4c-a3bdcfe2c62b"
      },
      "source": [
        "model.output_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15N3nZp4HrjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JrfPGcEJ7fu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "71d9b7a2-29c5-4e79-d89a-f3e1fcad016f"
      },
      "source": [
        "#model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 300, 50)           500050    \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               314368    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 814,675\n",
            "Trainable params: 814,675\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE91JicQKB3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "fc96a789-b0c3-44bd-d157-e97a5e108ad6"
      },
      "source": [
        "#train te model\n",
        "model.fit(X_train, y_train, \n",
        "          batch_size=32, \n",
        "          epochs=20, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "625/625 [==============================] - 278s 445ms/step - loss: 0.4799 - accuracy: 0.7652 - val_loss: 0.3377 - val_accuracy: 0.8602\n",
            "Epoch 2/20\n",
            "625/625 [==============================] - 277s 444ms/step - loss: 0.3634 - accuracy: 0.8510 - val_loss: 0.3559 - val_accuracy: 0.8604\n",
            "Epoch 3/20\n",
            "625/625 [==============================] - 275s 440ms/step - loss: 0.3047 - accuracy: 0.8784 - val_loss: 0.3800 - val_accuracy: 0.8492\n",
            "Epoch 4/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.2499 - accuracy: 0.9028 - val_loss: 0.3718 - val_accuracy: 0.8574\n",
            "Epoch 5/20\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.1777 - accuracy: 0.9358 - val_loss: 0.3409 - val_accuracy: 0.8698\n",
            "Epoch 6/20\n",
            "625/625 [==============================] - 275s 440ms/step - loss: 0.1332 - accuracy: 0.9529 - val_loss: 0.4293 - val_accuracy: 0.8658\n",
            "Epoch 7/20\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.1342 - accuracy: 0.9523 - val_loss: 0.4167 - val_accuracy: 0.8640\n",
            "Epoch 8/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.1075 - accuracy: 0.9617 - val_loss: 0.4707 - val_accuracy: 0.8562\n",
            "Epoch 9/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.0728 - accuracy: 0.9754 - val_loss: 0.5304 - val_accuracy: 0.8350\n",
            "Epoch 10/20\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.0623 - accuracy: 0.9788 - val_loss: 0.5936 - val_accuracy: 0.8624\n",
            "Epoch 11/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.5884 - val_accuracy: 0.8550\n",
            "Epoch 12/20\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.0394 - accuracy: 0.9870 - val_loss: 0.7214 - val_accuracy: 0.8518\n",
            "Epoch 13/20\n",
            "625/625 [==============================] - 274s 439ms/step - loss: 0.0500 - accuracy: 0.9845 - val_loss: 0.6885 - val_accuracy: 0.8610\n",
            "Epoch 14/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.0431 - accuracy: 0.9857 - val_loss: 0.6331 - val_accuracy: 0.8606\n",
            "Epoch 15/20\n",
            "625/625 [==============================] - 273s 437ms/step - loss: 0.0251 - accuracy: 0.9922 - val_loss: 0.6940 - val_accuracy: 0.8542\n",
            "Epoch 16/20\n",
            "625/625 [==============================] - 274s 438ms/step - loss: 0.0195 - accuracy: 0.9945 - val_loss: 0.7076 - val_accuracy: 0.8558\n",
            "Epoch 17/20\n",
            "625/625 [==============================] - 273s 437ms/step - loss: 0.0227 - accuracy: 0.9927 - val_loss: 0.7407 - val_accuracy: 0.8468\n",
            "Epoch 18/20\n",
            "625/625 [==============================] - 272s 436ms/step - loss: 0.0258 - accuracy: 0.9923 - val_loss: 0.7614 - val_accuracy: 0.8502\n",
            "Epoch 19/20\n",
            "625/625 [==============================] - 273s 437ms/step - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.7705 - val_accuracy: 0.8580\n",
            "Epoch 20/20\n",
            "625/625 [==============================] - 273s 437ms/step - loss: 0.0181 - accuracy: 0.9943 - val_loss: 0.8150 - val_accuracy: 0.8524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fad50f15b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Skx8Gg2tKpF7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "dbe52f3d-6820-406f-f912-e8fb3aeffb01"
      },
      "source": [
        "model.evaluate(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "625/625 [==============================] - 44s 71ms/step - loss: 0.0049 - accuracy: 0.9990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.004863114561885595, 0.9990000128746033]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fKHx1_ihjlx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3856d2ba-ddee-41ca-8360-78ea54b0396a"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 11s 69ms/step - loss: 0.8150 - accuracy: 0.8524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8150085806846619, 0.852400004863739]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    }
  ]
}