{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_"
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efNjNImfOIUC"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5450,
     "status": "ok",
     "timestamp": 1579423323252,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "l9C4aAIGOIUH",
    "outputId": "bc90bbe9-a55b-4ee4-d2f9-fd75737384c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 68,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ"
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XA1WsFSeOIUS"
   },
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5410,
     "status": "ok",
     "timestamp": 1579423323260,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "tmOnjVEYWhJi",
    "outputId": "90616943-aaa7-4fff-a353-31730b75539b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainX : (60000, 28, 28)\n",
      "Shape of trainY: (60000,)\n",
      "Shape of testX : (10000, 28, 28)\n",
      "Shape of testY: (10000,)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of trainX : {}\\nShape of trainY: {}'.format(trainX.shape, trainY.shape))\n",
    "print('Shape of testX : {}\\nShape of testY: {}'.format(testX.shape, testY.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5387,
     "status": "ok",
     "timestamp": 1579423323261,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "oYxVFm1sLUcB",
    "outputId": "e5e508aa-909e-4a2b-97a3-7f2754a23f1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of trainX : uint8\n",
      "dtype of trainY: uint8\n",
      "dtype of testX : uint8\n",
      "dtype of testY: uint8\n"
     ]
    }
   ],
   "source": [
    "print('dtype of trainX : {}\\ndtype of trainY: {}'.format(trainX.dtype, trainY.dtype))\n",
    "print('dtype of testX : {}\\ndtype of testY: {}'.format(testX.dtype, testY.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5360,
     "status": "ok",
     "timestamp": 1579423323262,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "ZzdZKBbYW6uI",
    "outputId": "ebe1fba2-0cc9-4b30-a191-770b6ab99195"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5330,
     "status": "ok",
     "timestamp": 1579423323263,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "UbiHj5YPOIUc",
    "outputId": "d82d0d69-e671-4098-8c7a-8aae4ad52080"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5293,
     "status": "ok",
     "timestamp": 1579423323264,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "eq6KYMbnOtDj",
    "outputId": "02624451-727b-4059-be02-cc4b3830a855"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "#unique classes in dataset\n",
    "print(np.unique(testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj"
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdKNg_okjuWe"
   },
   "outputs": [],
   "source": [
    "#Take a copy of trainY and testY as we are one-hot encoding the labels\n",
    "trainlabelsY = trainY\n",
    "testlabelsY = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "#Convert trainY and testY into one-hot encoded vectors.The dtype also changes to float32\n",
    "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
    "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5236,
     "status": "ok",
     "timestamp": 1579423323271,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "RHV3b9mzOIUq",
    "outputId": "92740652-0bb3-4000-9bc5-5dcea4af11e5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of trainY: (60000, 10)\n",
      "dtype of trainY: float32\n",
      "First 5 examples in trainY now are: \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Check trainY shape, dtype is float32, values are 0 and 1\n",
    "print('Shape of trainY:', trainY.shape)\n",
    "print('dtype of trainY:', trainY.dtype)\n",
    "print('First 5 examples in trainY now are: \\n', trainY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5219,
     "status": "ok",
     "timestamp": 1579423323272,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "RNNXoui8aQ3w",
    "outputId": "7afcc0e6-32ec-44c2-dffe-26535a5b93b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of testY: (10000, 10)\n",
      "dtype of testY: float32\n",
      "First 5 examples in testY now are:\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#Check testY shape, dtype is float32, values are 0 and 1\n",
    "print('Shape of testY:', testY.shape)\n",
    "print('dtype of testY:', testY.dtype)\n",
    "print('First 5 examples in testY now are:\\n', testY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AvDML2OoOIUx"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5192,
     "status": "ok",
     "timestamp": 1579423323274,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "3AsLFYvDpnjC",
    "outputId": "89d57151-493d-4d31-b707-207972b3ad93"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAABICAYAAADF252hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny/j/mB1+6NFd2+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 0 0 3 0 2 7 2 5]\n"
     ]
    }
   ],
   "source": [
    "#using imshow method in matlpotlib.image print the first 10 images in trainingset - from trainX\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(10):    \n",
    "    plt.subplot(2, 10, i + 1)    \n",
    "    plt.imshow(trainX[i,:].reshape([28,28]), cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "#Also print the labels for the first 10 images in trainingset - from trainY\n",
    "print(trainlabelsY[0:9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4"
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ac06XZZTOIU6"
   },
   "outputs": [],
   "source": [
    "#Building a Neural Network without Batch Normalization\n",
    "\n",
    "#Initialize Sequential model\n",
    "model1 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model1.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model1.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd optimizer\n",
    "model1.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_"
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 90206,
     "status": "ok",
     "timestamp": 1579423408324,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "O59C_-IgOIVB",
    "outputId": "349d5e2c-3aa5-447e-ae73-09603e5a6159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 3s 50us/sample - loss: 2020.4083 - acc: 0.7412 - val_loss: 1385.7173 - val_acc: 0.7801\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1592.0470 - acc: 0.7786 - val_loss: 1246.4447 - val_acc: 0.7758\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1548.6161 - acc: 0.7843 - val_loss: 974.7880 - val_acc: 0.8177\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1552.1905 - acc: 0.7875 - val_loss: 1422.3983 - val_acc: 0.7882\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1473.1250 - acc: 0.7930 - val_loss: 1133.7114 - val_acc: 0.8104\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1479.7200 - acc: 0.7945 - val_loss: 1053.8536 - val_acc: 0.8051\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1453.2756 - acc: 0.7951 - val_loss: 1816.4008 - val_acc: 0.7496\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1478.4634 - acc: 0.7958 - val_loss: 993.5058 - val_acc: 0.8210\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1414.3297 - acc: 0.8008 - val_loss: 1464.8447 - val_acc: 0.8136\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1441.2830 - acc: 0.8004 - val_loss: 1570.0541 - val_acc: 0.7859\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1431.0233 - acc: 0.8011 - val_loss: 1169.6066 - val_acc: 0.8008\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1460.2911 - acc: 0.8019 - val_loss: 1134.1122 - val_acc: 0.7971\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1427.8317 - acc: 0.8019 - val_loss: 2971.5426 - val_acc: 0.7488\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1432.7113 - acc: 0.8026 - val_loss: 1221.3336 - val_acc: 0.7894\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1387.9020 - acc: 0.8033 - val_loss: 1761.3277 - val_acc: 0.7448\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1373.7109 - acc: 0.8045 - val_loss: 3431.3280 - val_acc: 0.7026\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1369.5544 - acc: 0.8037 - val_loss: 1142.0366 - val_acc: 0.7942\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1410.0741 - acc: 0.8037 - val_loss: 1171.6196 - val_acc: 0.8156\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1414.1383 - acc: 0.8050 - val_loss: 1260.8668 - val_acc: 0.7837\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1400.0715 - acc: 0.8044 - val_loss: 1236.4465 - val_acc: 0.7631\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1408.5306 - acc: 0.8063 - val_loss: 1988.1623 - val_acc: 0.7221\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1402.3830 - acc: 0.8054 - val_loss: 1193.8025 - val_acc: 0.8090\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 3s 46us/sample - loss: 1417.5058 - acc: 0.8065 - val_loss: 1531.7334 - val_acc: 0.7774\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1424.4670 - acc: 0.8073 - val_loss: 1835.9345 - val_acc: 0.7795\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1376.7370 - acc: 0.8056 - val_loss: 1436.7611 - val_acc: 0.8075\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1374.7675 - acc: 0.8067 - val_loss: 1766.5752 - val_acc: 0.7717\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1355.5283 - acc: 0.8066 - val_loss: 1613.0783 - val_acc: 0.7575\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1391.0668 - acc: 0.8057 - val_loss: 1863.6720 - val_acc: 0.7733\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 3s 47us/sample - loss: 1341.6689 - acc: 0.8112 - val_loss: 1816.0679 - val_acc: 0.7969\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 3s 48us/sample - loss: 1349.0083 - acc: 0.8075 - val_loss: 1892.1327 - val_acc: 0.7588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf3f3f2e8>"
      ]
     },
     "execution_count": 83,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model1.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dE2xqnqsvWnI"
   },
   "source": [
    "#### Observations:\n",
    "- Without using BatchNormalization layer the trainingset is not normalized, so the data is not scaled\n",
    "- We observe that the training and validation loss is not reducing much and after 30 epochs the loss for trainingset is 1349 and for validationset is  1892, which is very high\n",
    "- Also the validationset accuracy is only 75.8%\n",
    "- So we should normalize the data using BatchNormalization layer to minimize the loss and get better accuracy\n",
    "- In this model we have not added any hidden layers between the input and output layers, used sgd optmizer with default learning rate of 0.01, accuracy as the metrics and categorical_crossentropy as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF"
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kndfpdidOIVI"
   },
   "outputs": [],
   "source": [
    "#Building a Neural Network with Batch Normalization layer\n",
    "\n",
    "#Initialize Sequential model\n",
    "model2 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model2.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer\n",
    "model2.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model2.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd optimizer\n",
    "model2.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 204356,
     "status": "ok",
     "timestamp": 1579423522506,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "JNLR8tcBOIVP",
    "outputId": "70b18220-9223-44f7-d433-a218ba457db2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.5981 - acc: 0.7922 - val_loss: 0.5310 - val_acc: 0.8190\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4894 - acc: 0.8307 - val_loss: 0.4908 - val_acc: 0.8328\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4687 - acc: 0.8394 - val_loss: 0.4944 - val_acc: 0.8332\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4560 - acc: 0.8422 - val_loss: 0.4876 - val_acc: 0.8341\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4505 - acc: 0.8440 - val_loss: 0.4872 - val_acc: 0.8368\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.4420 - acc: 0.8463 - val_loss: 0.4854 - val_acc: 0.8370\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.4408 - acc: 0.8479 - val_loss: 0.4903 - val_acc: 0.8373\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 67us/sample - loss: 0.4368 - acc: 0.8482 - val_loss: 0.4755 - val_acc: 0.8396\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4317 - acc: 0.8506 - val_loss: 0.4619 - val_acc: 0.8411\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4304 - acc: 0.8508 - val_loss: 0.4875 - val_acc: 0.8399\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4311 - acc: 0.8512 - val_loss: 0.4745 - val_acc: 0.8405\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4261 - acc: 0.8514 - val_loss: 0.4809 - val_acc: 0.8390\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4246 - acc: 0.8503 - val_loss: 0.4816 - val_acc: 0.8415\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4223 - acc: 0.8534 - val_loss: 0.4646 - val_acc: 0.8419\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4225 - acc: 0.8522 - val_loss: 0.4800 - val_acc: 0.8375\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4202 - acc: 0.8525 - val_loss: 0.4730 - val_acc: 0.8405\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4201 - acc: 0.8539 - val_loss: 0.4782 - val_acc: 0.8397\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4191 - acc: 0.8539 - val_loss: 0.4771 - val_acc: 0.8395\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4192 - acc: 0.8538 - val_loss: 0.4664 - val_acc: 0.8418\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4165 - acc: 0.8537 - val_loss: 0.4630 - val_acc: 0.8401\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4175 - acc: 0.8532 - val_loss: 0.4711 - val_acc: 0.8451\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4116 - acc: 0.8565 - val_loss: 0.4718 - val_acc: 0.8372\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4135 - acc: 0.8549 - val_loss: 0.4792 - val_acc: 0.8383\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4136 - acc: 0.8551 - val_loss: 0.4735 - val_acc: 0.8404\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4139 - acc: 0.8547 - val_loss: 0.4730 - val_acc: 0.8422\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4134 - acc: 0.8547 - val_loss: 0.4620 - val_acc: 0.8436\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4150 - acc: 0.8536 - val_loss: 0.4816 - val_acc: 0.8396\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4117 - acc: 0.8557 - val_loss: 0.4796 - val_acc: 0.8422\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4125 - acc: 0.8555 - val_loss: 0.4828 - val_acc: 0.8434\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4094 - acc: 0.8563 - val_loss: 0.4633 - val_acc: 0.8430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fce001426d8>"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model2.fit(trainX, trainY, \n",
    "          validation_data=(testX, testY), \n",
    "          epochs=30,\n",
    "          batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3R1SpnHlAHWr"
   },
   "source": [
    "#### Observations:\n",
    "- After using BatchNormalization layer the trainingset is normalized, so the data is now scaled\n",
    "- We observe that the training and validation loss is now reducing more and after 30 epochs the loss is minimized to a good extent and the accuracy also has increased a lot\n",
    "- Loss for trainingset is 0.41 and for validationset is 0.46, after 30 epochs, which is very less.So the loss has minimized\n",
    "- The validationset accuracy is 84.3% which is much more compared to 75.8% obtained from model1\n",
    "- This model shows that we always need to normalize the data using BatchNormalization layer before we build the model\n",
    "- In this model we have not added any hidden layers between the input and output layers, used sgd optmizer with default learning rate of 0.01, accuracy as the metrics and categorical_crossentropy as the loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "#Build a Neural Network with learning rate set to 0.001 in sgd optimizer\n",
    "\n",
    "#Initialize Sequential model\n",
    "model3 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model3.add(tf.keras.layers.Reshape((784,), input_shape=(28,28,)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer\n",
    "model3.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs after applying softmax as we have 10 classes\n",
    "model3.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "#Customize the learning rate to 0.001 in sgd optimizer\n",
    "sgd_optimizer = tf.keras.optimizers.SGD(learning_rate=0.001)\n",
    "\n",
    "#Compile the model with a cross entropy loss function and sgd_optimizer with lr=0.001\n",
    "model3.compile(optimizer=sgd_optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bv63ZySUwUdg"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 318017,
     "status": "ok",
     "timestamp": 1579423636199,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "pJUqA5T4OIVc",
    "outputId": "edb17104-ee47-40bb-d624-2904607f839d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.9307 - acc: 0.6877 - val_loss: 0.6820 - val_acc: 0.7679\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.6432 - acc: 0.7789 - val_loss: 0.6087 - val_acc: 0.7934\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5881 - acc: 0.7962 - val_loss: 0.5858 - val_acc: 0.8039\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.5601 - acc: 0.8073 - val_loss: 0.5528 - val_acc: 0.8106\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5418 - acc: 0.8122 - val_loss: 0.5388 - val_acc: 0.8137\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.5276 - acc: 0.8194 - val_loss: 0.5319 - val_acc: 0.8172\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.5152 - acc: 0.8236 - val_loss: 0.5266 - val_acc: 0.8186\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5085 - acc: 0.8248 - val_loss: 0.5138 - val_acc: 0.8226\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.5023 - acc: 0.8264 - val_loss: 0.5099 - val_acc: 0.8240\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4937 - acc: 0.8297 - val_loss: 0.5097 - val_acc: 0.8249\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4901 - acc: 0.8306 - val_loss: 0.5015 - val_acc: 0.8263\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4837 - acc: 0.8338 - val_loss: 0.5160 - val_acc: 0.8262\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4847 - acc: 0.8338 - val_loss: 0.4987 - val_acc: 0.8282\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4778 - acc: 0.8349 - val_loss: 0.4977 - val_acc: 0.8287\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4747 - acc: 0.8375 - val_loss: 0.4897 - val_acc: 0.8297\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4717 - acc: 0.8389 - val_loss: 0.4875 - val_acc: 0.8318\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4703 - acc: 0.8381 - val_loss: 0.4914 - val_acc: 0.8301\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4672 - acc: 0.8404 - val_loss: 0.4883 - val_acc: 0.8294\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4654 - acc: 0.8385 - val_loss: 0.4854 - val_acc: 0.8323\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4636 - acc: 0.8413 - val_loss: 0.4808 - val_acc: 0.8326\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4607 - acc: 0.8422 - val_loss: 0.4792 - val_acc: 0.8326\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4578 - acc: 0.8426 - val_loss: 0.4778 - val_acc: 0.8328\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4586 - acc: 0.8420 - val_loss: 0.4789 - val_acc: 0.8322\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4567 - acc: 0.8430 - val_loss: 0.4767 - val_acc: 0.8342\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4550 - acc: 0.8434 - val_loss: 0.4900 - val_acc: 0.8349\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4519 - acc: 0.8445 - val_loss: 0.4869 - val_acc: 0.8346\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 4s 63us/sample - loss: 0.4516 - acc: 0.8442 - val_loss: 0.4777 - val_acc: 0.8351\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4517 - acc: 0.8450 - val_loss: 0.4747 - val_acc: 0.8352\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4481 - acc: 0.8474 - val_loss: 0.4709 - val_acc: 0.8349\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 4s 64us/sample - loss: 0.4484 - acc: 0.8463 - val_loss: 0.4699 - val_acc: 0.8365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf3dcbda0>"
      ]
     },
     "execution_count": 87,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model3.fit(trainX, trainY, \n",
    "           validation_data=(testX,testY),\n",
    "           epochs=30, \n",
    "           batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hvHa_UTAEYfq"
   },
   "source": [
    "#### Observations:\n",
    "- In this model we have not added any hidden layers between the input and output layers, used an sgd optmizer with learning rate of 0.001, accuracy as the metrics and categorical_crossentropy as the loss function\n",
    "- We observe that there is no much change in the training and validation loss and the accuracy is also slightly less.\n",
    "- This is because, we have lowered the learning rate by 10% from 0.01 to 0.001 and so the gradient descent optimizer will take more number of iterations(epochs) for converging the loss function to a minimum value.\n",
    "- Loss for trainingset is 0.45 and for validationset is 0.47, after 30 epochs,so the loss has minimized\n",
    "- The validationset accuracy is 83.6% which is slightly less compared to 84.3% obtained from model2\n",
    "- This model shows that if we reduce the learning rate the number of iterations required for the loss function to converge to a minimum value will be more and so we have to increase the number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk"
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and sigmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "#Build a Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer\n",
    "#Use cross entropy loss function and sigmoid as activation in the hidden layers\n",
    "#Use softmax as activation function in the output layer\n",
    "#Use sgd optimizer with learning rate 0.03\n",
    "\n",
    "#Initialize Sequential model\n",
    "model4 = tf.keras.models.Sequential()\n",
    "\n",
    "#Reshape input data from 2D to 1D -> 28x28 to 784\n",
    "model4.add(tf.keras.layers.Reshape(target_shape=(784,), input_shape=(28,28)))\n",
    "\n",
    "#Normalize the data with BatchNormalization layer()\n",
    "model4.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 1 with 100 neurons and activation function as sigmoid \n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 2 with 100 neurons and activation function as sigmoid\n",
    "model4.add(tf.keras.layers.Dense(100, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer, Hidden Layer 3 with 10 neurons and activation function as sigmoid\n",
    "model4.add(tf.keras.layers.Dense(10, activation='sigmoid'))\n",
    "\n",
    "#Add Dense Layer which provides 10 Outputs as we have 10 classes after 3 Hidden layers by applying activation function as softmax \n",
    "model4.add(tf.keras.layers.Dense(10, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MQ7oIymROIVp"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-O-fFxnOIVt"
   },
   "outputs": [],
   "source": [
    "#Use cross entropy loss function\n",
    "#Use sgd optimizer with learning rate 0.03\n",
    "\n",
    "sgd_optimizer2 = tf.keras.optimizers.SGD(learning_rate=0.03)\n",
    "model4.compile(optimizer=sgd_optimizer2, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BS7L5Z2c7U-J"
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479522,
     "status": "ok",
     "timestamp": 1579423797767,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "BiP7IL52OIVw",
    "outputId": "78052514-5600-4ced-8894-319f1ca7531f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/30\n",
      "60000/60000 [==============================] - 6s 95us/sample - loss: 1.8136 - acc: 0.4078 - val_loss: 1.3095 - val_acc: 0.5440\n",
      "Epoch 2/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 1.1423 - acc: 0.6119 - val_loss: 0.9652 - val_acc: 0.6788\n",
      "Epoch 3/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.8679 - acc: 0.7128 - val_loss: 0.7662 - val_acc: 0.7464\n",
      "Epoch 4/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.7173 - acc: 0.7583 - val_loss: 0.6529 - val_acc: 0.7740\n",
      "Epoch 5/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.6260 - acc: 0.7815 - val_loss: 0.5836 - val_acc: 0.7922\n",
      "Epoch 6/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.5684 - acc: 0.8004 - val_loss: 0.5459 - val_acc: 0.8028\n",
      "Epoch 7/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.5271 - acc: 0.8209 - val_loss: 0.5121 - val_acc: 0.8248\n",
      "Epoch 8/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4960 - acc: 0.8324 - val_loss: 0.4838 - val_acc: 0.8329\n",
      "Epoch 9/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4666 - acc: 0.8418 - val_loss: 0.4669 - val_acc: 0.8382\n",
      "Epoch 10/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4431 - acc: 0.8497 - val_loss: 0.4479 - val_acc: 0.8456\n",
      "Epoch 11/30\n",
      "60000/60000 [==============================] - 6s 92us/sample - loss: 0.4241 - acc: 0.8548 - val_loss: 0.4338 - val_acc: 0.8492\n",
      "Epoch 12/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4095 - acc: 0.8588 - val_loss: 0.4216 - val_acc: 0.8541\n",
      "Epoch 13/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3954 - acc: 0.8637 - val_loss: 0.4161 - val_acc: 0.8550\n",
      "Epoch 14/30\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3838 - acc: 0.8676 - val_loss: 0.4069 - val_acc: 0.8581\n",
      "Epoch 15/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3722 - acc: 0.8708 - val_loss: 0.4014 - val_acc: 0.8612\n",
      "Epoch 16/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3609 - acc: 0.8743 - val_loss: 0.3936 - val_acc: 0.8646\n",
      "Epoch 17/30\n",
      "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3526 - acc: 0.8771 - val_loss: 0.3890 - val_acc: 0.8639\n",
      "Epoch 18/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.3416 - acc: 0.8819 - val_loss: 0.3845 - val_acc: 0.8673\n",
      "Epoch 19/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3360 - acc: 0.8826 - val_loss: 0.3784 - val_acc: 0.8683\n",
      "Epoch 20/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3296 - acc: 0.8838 - val_loss: 0.3741 - val_acc: 0.8703\n",
      "Epoch 21/30\n",
      "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3205 - acc: 0.8880 - val_loss: 0.3863 - val_acc: 0.8646\n",
      "Epoch 22/30\n",
      "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3126 - acc: 0.8912 - val_loss: 0.3684 - val_acc: 0.8699\n",
      "Epoch 23/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3084 - acc: 0.8920 - val_loss: 0.3615 - val_acc: 0.8738\n",
      "Epoch 24/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.3006 - acc: 0.8949 - val_loss: 0.3727 - val_acc: 0.8691\n",
      "Epoch 25/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2953 - acc: 0.8964 - val_loss: 0.3657 - val_acc: 0.8722\n",
      "Epoch 26/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2872 - acc: 0.8991 - val_loss: 0.3557 - val_acc: 0.8752\n",
      "Epoch 27/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2853 - acc: 0.8999 - val_loss: 0.3629 - val_acc: 0.8725\n",
      "Epoch 28/30\n",
      "60000/60000 [==============================] - 5s 89us/sample - loss: 0.2823 - acc: 0.9007 - val_loss: 0.3551 - val_acc: 0.8746\n",
      "Epoch 29/30\n",
      "60000/60000 [==============================] - 5s 87us/sample - loss: 0.2767 - acc: 0.9024 - val_loss: 0.3528 - val_acc: 0.8765\n",
      "Epoch 30/30\n",
      "60000/60000 [==============================] - 5s 88us/sample - loss: 0.2729 - acc: 0.9051 - val_loss: 0.3493 - val_acc: 0.8763\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fcdf3c05e48>"
      ]
     },
     "execution_count": 90,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the model on trainX,trainY and validate using testX,testY\n",
    "\n",
    "model4.fit(trainX, trainY,\n",
    "           validation_data=(testX, testY),\n",
    "           epochs=30,\n",
    "           batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mfoVOvpiKZGz"
   },
   "source": [
    "#### Observations:\n",
    "- In this model we have added 3 hidden layers between the input and output layers, used an sgd optmizer with learning rate of 0.03, accuracy as the metrics and categorical_crossentropy as the loss function\n",
    "- We observe that when the learning rate is increased three times from 0.01 to 0.03, there is a huge change in the training and validation loss and the accuracy is also increased.\n",
    "- This change is because, we have increased the learning rate to 0.03 and so the gradient descent optimizer will take less number of iterations(epochs) for converging the loss function to a minimum value.\n",
    "- Also, we have used sigmoid as activation function for building the neural networks and softmax as activation function to get the output layer for the probabilities to get evenly distributed for all classes.This is ideal for multi-class classification.\n",
    "- Loss for trainingset is 0.25 and for validationset is 0.35, after 30 epochs,so the loss has minimized\n",
    "- The validationset accuracy is 87.6% which is slightly less compared to 83.6% obtained from model3\n",
    "- This model shows that if we add hidden layers loss will be very minimal and also we get a good accuracy.\n",
    "- So model4 is the best model of all the four models we have built."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0"
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1215,
     "status": "ok",
     "timestamp": 1579428945730,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "h4ojW6-oOIV2",
    "outputId": "c23a219d-61b7-473c-aa75-00e75cf2a2fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_11 (Reshape)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 92,856\n",
      "Trainable params: 91,288\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#get model summary of total weights and bias\n",
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wjmDJbvomwGw"
   },
   "outputs": [],
   "source": [
    "#get all the weights obtained\n",
    "all_weights= model4.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5"
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1205,
     "status": "ok",
     "timestamp": 1579429249556,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "bIkbMEN5OIV7",
    "outputId": "abde1e4a-5512-41ce-e817-19e987c221d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 107,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Expand the dimensions of test data from 1D to 2D (784,1) to (28,28) \n",
    "input_data = np.expand_dims(testX[0], axis=0)\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1209,
     "status": "ok",
     "timestamp": 1579429314462,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "grWwAthTn5Fu",
    "outputId": "1dd1b4cd-cfb5-436b-80b0-557f48646a37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.7069038e-05, 7.8161725e-07, 2.5206429e-04, 2.3489063e-06,\n",
       "        2.0187224e-05, 2.9720282e-03, 9.2620132e-05, 3.9974996e-03,\n",
       "        2.8346665e-03, 9.8980075e-01]], dtype=float32)"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run the model on test data and get predicted probabilities\n",
    "pred = model4.predict(input_data)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1193,
     "status": "ok",
     "timestamp": 1579429762651,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "JNSffndyVzms",
    "outputId": "1f73ca85-3576-4e01-9eb0-71ef7ef8dfc3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sum of the predicted probabilities should be 1 as we have used softmax as activation function to get the output probabilities\n",
    "np.sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 479462,
     "status": "ok",
     "timestamp": 1579423797774,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "MnZuATpOn8L0",
    "outputId": "d56731c2-5cec-4e2a-8ccc-f46a471cabf6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10)"
      ]
     },
     "execution_count": 95,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of predicted probailities should be same as number of classes (1,10)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1144,
     "status": "ok",
     "timestamp": 1579429811807,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "qkWWqeOTo8cB",
    "outputId": "3c4900de-7fdf-4a17-fbbf-079234e1bdf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7069038e-05, 7.8161725e-07, 2.5206429e-04, 2.3489063e-06,\n",
       "       2.0187224e-05, 2.9720282e-03, 9.2620132e-05, 3.9974996e-03,\n",
       "       2.8346665e-03, 9.8980075e-01], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pred{0] is same as pred as there is only one row\n",
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1098,
     "status": "ok",
     "timestamp": 1579430344254,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "kwQsVa9apew6",
    "outputId": "0efd8a5e-8186-4811-c026-fa6993033595"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 117,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The Index of Maximum Probability outcome is the predicted value\n",
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1183,
     "status": "ok",
     "timestamp": 1579430359845,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "oKt8uPMLpoHk",
    "outputId": "6c89d033-cfe0-44ed-f366-e06afd14a6f2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 144x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the image of the predicted value\n",
    "plt.figure(figsize=(2,2))\n",
    "plt.imshow(testX[0],cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1181,
     "status": "ok",
     "timestamp": 1579430430409,
     "user": {
      "displayName": "Dinakar K.B.N",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mB6BhFIFQ26CUaEhDl16HhXxqj4NbZegPsO2xKMDQ=s64",
      "userId": "06643686747511876348"
     },
     "user_tz": -330
    },
    "id": "PldEwsoxp2uA",
    "outputId": "92c449fe-4610-4aa9-b747-d402fc4525cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 119,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate the predicted value to the actual value in testY\n",
    "np.argmax(testY[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6skW0a7-Y9wt"
   },
   "source": [
    "##### Using the model we are able to match predicted value with actual value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dBEQaDWHqEOg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "R6_ExternalLab_AIML-1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
