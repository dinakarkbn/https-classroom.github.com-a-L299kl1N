{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book recommendations based on similarity using Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Is1yLy_oj4Gu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "#set display width\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install gensim\n",
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding word embeddings in word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keyedvectors.load_word2vec_format is used to load pre-trained word2vec models\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "w2vec = KeyedVectors.load_word2vec_format(\"glove.6B.50d_orig.txt\", binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.45281 , -0.50108 , -0.53714 , -0.015697,  0.22191 ,  0.54602 ,\n",
       "       -0.67301 , -0.6891  ,  0.63493 , -0.19726 ,  0.33685 ,  0.7735  ,\n",
       "        0.90094 ,  0.38488 ,  0.38367 ,  0.2657  , -0.08057 ,  0.61089 ,\n",
       "       -1.2894  , -0.22313 , -0.61578 ,  0.21697 ,  0.35614 ,  0.44499 ,\n",
       "        0.60885 , -1.1633  , -1.1579  ,  0.36118 ,  0.10466 , -0.78325 ,\n",
       "        1.4352  ,  0.18629 , -0.26112 ,  0.83275 , -0.23123 ,  0.32481 ,\n",
       "        0.14485 , -0.44552 ,  0.33497 , -0.95946 , -0.097479,  0.48138 ,\n",
       "       -0.43352 ,  0.69455 ,  0.91043 , -0.28173 ,  0.41637 , -1.2609  ,\n",
       "        0.71278 ,  0.23782 ], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50 legth word embedding vector for the word 'cat'\n",
    "w2vec.word_vec(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11008  , -0.38781  , -0.57615  , -0.27714  ,  0.70521  ,\n",
       "        0.53994  , -1.0786   , -0.40146  ,  1.1504   , -0.5678   ,\n",
       "        0.0038977,  0.52878  ,  0.64561  ,  0.47262  ,  0.48549  ,\n",
       "       -0.18407  ,  0.1801   ,  0.91397  , -1.1979   , -0.5778   ,\n",
       "       -0.37985  ,  0.33606  ,  0.772    ,  0.75555  ,  0.45506  ,\n",
       "       -1.7671   , -1.0503   ,  0.42566  ,  0.41893  , -0.68327  ,\n",
       "        1.5673   ,  0.27685  , -0.61708  ,  0.64638  , -0.076996 ,\n",
       "        0.37118  ,  0.1308   , -0.45137  ,  0.25398  , -0.74392  ,\n",
       "       -0.086199 ,  0.24068  , -0.64819  ,  0.83549  ,  1.2502   ,\n",
       "       -0.51379  ,  0.04224  , -0.88118  ,  0.7158   ,  0.38519  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50 legth word embedding vector for the word 'dog'\n",
    "w2vec.word_vec('dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.20356 , -0.8707  , -0.19172 ,  0.73862 ,  0.18494 ,  0.14926 ,\n",
       "        0.48079 , -0.21633 ,  0.72753 , -0.36912 ,  0.13397 , -0.1143  ,\n",
       "       -0.18075 , -0.64683 , -0.18484 ,  0.83575 ,  0.48179 ,  0.76026 ,\n",
       "       -0.50381 ,  0.80743 ,  1.2195  ,  0.3459  ,  0.22185 ,  0.31335 ,\n",
       "        1.2066  , -1.8441  ,  0.14064 , -0.99715 , -1.1402  ,  0.32342 ,\n",
       "        3.2128  ,  0.42708 ,  0.19504 ,  0.80113 ,  0.38555 , -0.12568 ,\n",
       "       -0.26533 ,  0.055264, -1.1557  ,  0.16836 , -0.82228 ,  0.20394 ,\n",
       "        0.089235, -0.60125 , -0.032878,  1.3735  , -0.51661 ,  0.29611 ,\n",
       "        0.23951 , -1.3801  ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#50 legth word embedding vector can also be obtained by searching the model using key as the word\n",
    "w2vec['india']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = w2vec.word_vec(\"cat\")\n",
    "b = w2vec.word_vec(\"dog\")\n",
    "c = w2vec.word_vec(\"pen\")\n",
    "d = w2vec.word_vec(\"elephant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.92137766, 2.47113394399376e-21)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find similarity between two words using correlation between word embeddings\n",
    "from scipy.stats.stats import pearsonr\n",
    "pearsonr(a,b) #cat and dog are more similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.5345575, 6.366049389778326e-05),\n",
       " (0.50545216, 0.00018109233218871945),\n",
       " (0.73933697, 8.67745931811567e-10),\n",
       " (0.7144916, 5.638778596712443e-09),\n",
       " (0.27897468, 0.049774298949480114))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Find similarity between two words using correlation between word embeddings\n",
    "pearsonr(a,c), pearsonr(b,c), pearsonr(a,d), pearsonr(b,d), pearsonr(c,d) #all these are less similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dog', 0.9218006134033203),\n",
       " ('rabbit', 0.8487820625305176),\n",
       " ('monkey', 0.8041081428527832),\n",
       " ('rat', 0.7891963124275208),\n",
       " ('cats', 0.7865270376205444),\n",
       " ('snake', 0.7798910737037659),\n",
       " ('dogs', 0.7795814871788025),\n",
       " ('pet', 0.7792249917984009),\n",
       " ('mouse', 0.7731667757034302),\n",
       " ('bite', 0.7728800773620605)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most similar words to a given word using model.most_similar()\n",
    "w2vec.most_similar(\"cat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'car'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word which is not similar among a group of words\n",
    "w2vec.doesnt_match(\"pen car pencil ink\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reticulated', 0.6916365027427673),\n",
       " ('spamalot', 0.6635735630989075),\n",
       " ('php', 0.6414496898651123),\n",
       " ('owl', 0.6301496028900146),\n",
       " ('mouse', 0.6275478005409241),\n",
       " ('reticulatus', 0.6274471282958984),\n",
       " ('perl', 0.6267575621604919),\n",
       " ('monkey', 0.620721161365509),\n",
       " ('monty', 0.6079354286193848),\n",
       " ('scripting', 0.6041731834411621)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar_by_word is same as most_similar\n",
    "w2vec.similar_by_word(\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61270845"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similarity method gives the cosine similarity between two words\n",
    "w2vec.similarity('apple', 'mango')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Madras is NOT in the model\n"
     ]
    }
   ],
   "source": [
    "#check if a word is present in the word2vec model using model name\n",
    "word='Madras'\n",
    "if word in w2vec:\n",
    "    print('{0} is in the model'.format(word))\n",
    "else:\n",
    "    print('{0} is NOT in the model'.format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bhagyanagar is NOT in the model\n"
     ]
    }
   ],
   "source": [
    "#check if a word is present in the word2vec model using model.vocab\n",
    "word='Bhagyanagar'\n",
    "if word in w2vec.vocab:\n",
    "    print('{0} is in the model'.format(word))\n",
    "else:\n",
    "    print('{0} is NOT in the model'.format(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding sentence vectors from word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title1 = \"laws of physics\"\n",
    "title2 = \"theory of relativity\"\n",
    "title3 = \"battle of panipat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 50)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([w2vec.word_vec(x) for x in word_tokenize(title1) if x in w2vec.vocab]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.1832  , -0.91248 , -1.0874  , -0.52611 , -0.59133 ,  0.90597 ,\n",
       "         0.23737 , -1.2453  ,  0.31221 , -0.18614 ,  0.047556,  0.66195 ,\n",
       "         0.034929, -0.1288  ,  0.38821 ,  0.17066 , -0.13575 , -1.0389  ,\n",
       "         0.75063 , -0.41731 ,  0.71746 , -0.13975 , -0.54515 , -0.12073 ,\n",
       "        -0.40956 , -2.349   ,  0.065296, -0.82423 ,  0.51494 , -0.13903 ,\n",
       "         2.6371  , -0.28108 , -1.3046  , -1.2122  , -0.24492 , -0.25433 ,\n",
       "         0.3531  , -0.6155  , -0.5967  ,  0.52287 , -0.81452 , -0.034609,\n",
       "         1.631   ,  1.4932  , -0.77162 ,  0.065482, -0.56947 ,  0.19967 ,\n",
       "         0.82442 , -0.28176 ], dtype=float32),\n",
       " array([ 0.70853  ,  0.57088  , -0.4716   ,  0.18048  ,  0.54449  ,\n",
       "         0.72603  ,  0.18157  , -0.52393  ,  0.10381  , -0.17566  ,\n",
       "         0.078852 , -0.36216  , -0.11829  , -0.83336  ,  0.11917  ,\n",
       "        -0.16605  ,  0.061555 , -0.012719 , -0.56623  ,  0.013616 ,\n",
       "         0.22851  , -0.14396  , -0.067549 , -0.38157  , -0.23698  ,\n",
       "        -1.7037   , -0.86692  , -0.26704  , -0.2589   ,  0.1767   ,\n",
       "         3.8676   , -0.1613   , -0.13273  , -0.68881  ,  0.18444  ,\n",
       "         0.0052464, -0.33874  , -0.078956 ,  0.24185  ,  0.36576  ,\n",
       "        -0.34727  ,  0.28483  ,  0.075693 , -0.062178 , -0.38988  ,\n",
       "         0.22902  , -0.21617  , -0.22562  , -0.093918 , -0.80375  ],\n",
       "       dtype=float32),\n",
       " array([-0.76028 ,  1.3048  , -0.086416, -0.092512, -0.19359 ,  0.10563 ,\n",
       "         0.70074 , -0.97941 , -0.57269 ,  0.68583 ,  0.91511 ,  0.28773 ,\n",
       "        -0.50195 ,  0.68386 , -0.11504 ,  0.07918 ,  0.28243 ,  1.404   ,\n",
       "        -1.0323  , -0.1534  ,  0.9346  ,  0.25864 ,  0.53605 , -0.44312 ,\n",
       "         0.81973 , -1.1146  , -0.71439 , -0.78889 , -1.0154  ,  0.40448 ,\n",
       "         1.5148  , -1.1208  , -0.94428 , -2.2462  ,  0.20003 , -0.1727  ,\n",
       "        -0.20429 ,  1.6377  ,  1.3617  ,  1.0111  ,  0.21541 , -0.50015 ,\n",
       "         0.26245 ,  0.96734 , -0.35057 ,  0.54879 ,  1.5572  ,  0.76885 ,\n",
       "        -0.54687 , -0.2338  ], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w2vec.word_vec(x) for x in word_tokenize(title1) if x in w2vec.vocab ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([w2vec.word_vec(x) for x in word_tokenize(title1) if x in w2vec.vocab]).mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41165003,  0.32106668, -0.548472  , -0.14604734, -0.08014334,\n",
       "        0.57921   ,  0.37322664, -0.91621333, -0.05222334,  0.10800999,\n",
       "        0.34717265,  0.19584   , -0.19510369, -0.09276666,  0.13078   ,\n",
       "        0.02793   ,  0.06941167,  0.11746033, -0.28263333, -0.18569799,\n",
       "        0.6268566 , -0.00835667, -0.02554965, -0.31514   ,  0.05773   ,\n",
       "       -1.7224334 , -0.505338  , -0.62672   , -0.25312   ,  0.14738333,\n",
       "        2.6731665 , -0.52106   , -0.79387   , -1.3824034 ,  0.04651667,\n",
       "       -0.14059454, -0.06331   ,  0.31441465,  0.33561668,  0.6332434 ,\n",
       "       -0.31546   , -0.08330967,  0.656381  ,  0.799454  , -0.5040233 ,\n",
       "        0.28109732,  0.25718665,  0.24763334,  0.06121065, -0.43976998],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([w2vec.word_vec(x) for x in word_tokenize(title1) if x in w2vec.vocab]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find vector representation for each title by splitting the title into indivdiual words. \n",
    "### Find vector for each word and average them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "title1_vec = np.array([w2vec.word_vec(x) for x in word_tokenize(title1) if x in w2vec.vocab]).mean(axis=0)\n",
    "title2_vec = np.array([w2vec.word_vec(x) for x in word_tokenize(title2) if x in w2vec.vocab]).mean(axis=0)\n",
    "title3_vec = np.array([w2vec.word_vec(x) for x in word_tokenize(title3) if x in w2vec.vocab]).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,) (50,) (50,)\n"
     ]
    }
   ],
   "source": [
    "print(title1_vec.shape, title2_vec.shape, title3_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FInd the pearson correlation between different titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8310373, 8.078668933786241e-14)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(title1_vec,title2_vec) # title1 and title2 are very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.49981984, 0.00021934156127459731)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(title1_vec,title3_vec) # title1 and title3 are not similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.48349163, 0.0003753143672253442)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(title2_vec,title3_vec) # title2 and title3 are not similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tWaFfCoNj4Hz"
   },
   "source": [
    "### Book Recommendations - Finding  most similiar books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oFFg6e05j4Hz"
   },
   "outputs": [],
   "source": [
    "books_data = pd.read_csv('books.csv',encoding=\"latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'category'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e</td>\n",
       "      <td>Medical Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barron's GRE, 21st Edition</td>\n",
       "      <td>Test Preparation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Balanchine: The Ballet Maker (Eminent Lives)</td>\n",
       "      <td>Biographies &amp; Memoirs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Partner in Holiness: Deepening Mindfulness, Practicing Compassion and Enriching Our Lives Through the Wisdom of R. Levi Yitzhak of Berdichev's, Vol. 2  (Institute for Jewish Spirituality)</td>\n",
       "      <td>Religion &amp; Spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Construction Scheduling: Principles and Practices (2nd Edition)</td>\n",
       "      <td>Arts &amp; Photography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Literature and Its Writers: A Compact Introduction to Fiction, Poetry, and Drama</td>\n",
       "      <td>Literature &amp; Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Straight on Till Morning: The Life of Beryl Markham</td>\n",
       "      <td>Engineering &amp; Transportation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diagrammatica: The Path to Feynman Diagrams (Cambridge Lecture Notes in Physics)</td>\n",
       "      <td>Science &amp; Math</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Book of Common Prayer 1979: Large Print edition</td>\n",
       "      <td>Christian Books &amp; Bibles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Handful of Stars</td>\n",
       "      <td>Children's Books</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           title  \\\n",
       "0  Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e                                                                                                                                 \n",
       "1  Barron's GRE, 21st Edition                                                                                                                                                                      \n",
       "2  George Balanchine: The Ballet Maker (Eminent Lives)                                                                                                                                             \n",
       "3  A Partner in Holiness: Deepening Mindfulness, Practicing Compassion and Enriching Our Lives Through the Wisdom of R. Levi Yitzhak of Berdichev's, Vol. 2  (Institute for Jewish Spirituality)   \n",
       "4  Construction Scheduling: Principles and Practices (2nd Edition)                                                                                                                                 \n",
       "5  Literature and Its Writers: A Compact Introduction to Fiction, Poetry, and Drama                                                                                                                \n",
       "6  Straight on Till Morning: The Life of Beryl Markham                                                                                                                                             \n",
       "7  Diagrammatica: The Path to Feynman Diagrams (Cambridge Lecture Notes in Physics)                                                                                                                \n",
       "8  Book of Common Prayer 1979: Large Print edition                                                                                                                                                 \n",
       "9  A Handful of Stars                                                                                                                                                                              \n",
       "\n",
       "                       category  \n",
       "0  Medical Books                 \n",
       "1  Test Preparation              \n",
       "2  Biographies & Memoirs         \n",
       "3  Religion & Spirituality       \n",
       "4  Arts & Photography            \n",
       "5  Literature & Fiction          \n",
       "6  Engineering & Transportation  \n",
       "7  Science & Math                \n",
       "8  Christian Books & Bibles      \n",
       "9  Children's Books              "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkHdex0fj4H9"
   },
   "outputs": [],
   "source": [
    "#clean the title column, convert all to lower case and remove non alpha characters\n",
    "\n",
    "import re\n",
    "books_data[\"title_clean\"] = [re.sub(\"[^a-zA-Z ]\",\"\",x).lower() for x in books_data[\"title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>title_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e</td>\n",
       "      <td>oral and maxillofacial surgery an objectivebased textbook e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Barron's GRE, 21st Edition</td>\n",
       "      <td>barrons gre st edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>George Balanchine: The Ballet Maker (Eminent Lives)</td>\n",
       "      <td>george balanchine the ballet maker eminent lives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Partner in Holiness: Deepening Mindfulness, Practicing Compassion and Enriching Our Lives Through the Wisdom of R. Levi Yitzhak of Berdichev's, Vol. 2  (Institute for Jewish Spirituality)</td>\n",
       "      <td>a partner in holiness deepening mindfulness practicing compassion and enriching our lives through the wisdom of r levi yitzhak of berdichevs vol   institute for jewish spirituality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Construction Scheduling: Principles and Practices (2nd Edition)</td>\n",
       "      <td>construction scheduling principles and practices nd edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Literature and Its Writers: A Compact Introduction to Fiction, Poetry, and Drama</td>\n",
       "      <td>literature and its writers a compact introduction to fiction poetry and drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Straight on Till Morning: The Life of Beryl Markham</td>\n",
       "      <td>straight on till morning the life of beryl markham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Diagrammatica: The Path to Feynman Diagrams (Cambridge Lecture Notes in Physics)</td>\n",
       "      <td>diagrammatica the path to feynman diagrams cambridge lecture notes in physics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Book of Common Prayer 1979: Large Print edition</td>\n",
       "      <td>book of common prayer  large print edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>A Handful of Stars</td>\n",
       "      <td>a handful of stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                           title  \\\n",
       "0  Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e                                                                                                                                 \n",
       "1  Barron's GRE, 21st Edition                                                                                                                                                                      \n",
       "2  George Balanchine: The Ballet Maker (Eminent Lives)                                                                                                                                             \n",
       "3  A Partner in Holiness: Deepening Mindfulness, Practicing Compassion and Enriching Our Lives Through the Wisdom of R. Levi Yitzhak of Berdichev's, Vol. 2  (Institute for Jewish Spirituality)   \n",
       "4  Construction Scheduling: Principles and Practices (2nd Edition)                                                                                                                                 \n",
       "5  Literature and Its Writers: A Compact Introduction to Fiction, Poetry, and Drama                                                                                                                \n",
       "6  Straight on Till Morning: The Life of Beryl Markham                                                                                                                                             \n",
       "7  Diagrammatica: The Path to Feynman Diagrams (Cambridge Lecture Notes in Physics)                                                                                                                \n",
       "8  Book of Common Prayer 1979: Large Print edition                                                                                                                                                 \n",
       "9  A Handful of Stars                                                                                                                                                                              \n",
       "\n",
       "                                                                                                                                                                            title_clean  \n",
       "0  oral and maxillofacial surgery an objectivebased textbook e                                                                                                                           \n",
       "1  barrons gre st edition                                                                                                                                                                \n",
       "2  george balanchine the ballet maker eminent lives                                                                                                                                      \n",
       "3  a partner in holiness deepening mindfulness practicing compassion and enriching our lives through the wisdom of r levi yitzhak of berdichevs vol   institute for jewish spirituality  \n",
       "4  construction scheduling principles and practices nd edition                                                                                                                           \n",
       "5  literature and its writers a compact introduction to fiction poetry and drama                                                                                                         \n",
       "6  straight on till morning the life of beryl markham                                                                                                                                    \n",
       "7  diagrammatica the path to feynman diagrams cambridge lecture notes in physics                                                                                                         \n",
       "8  book of common prayer  large print edition                                                                                                                                            \n",
       "9  a handful of stars                                                                                                                                                                    "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_data[[\"title\",\"title_clean\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bl_EUgIFj4H_",
    "outputId": "71831e49-41eb-436d-878c-46b814bbc4c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5700 [00:00<?, ?it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: Mean of empty slice.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 5700/5700 [00:00<00:00, 16546.94it/s]\n"
     ]
    }
   ],
   "source": [
    "#finding Word Vector representation of all book titles using w2vec\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "title_vec = np.zeros((books_data.shape[0],50))\n",
    "#title_vec = np.zeros((100,50))\n",
    "#print(title_vec[0])\n",
    "\n",
    "for i in tqdm(range(0,books_data.shape[0])):\n",
    "#for i in tqdm(range(0,100)):\n",
    "\n",
    "    words = books_data[\"title_clean\"].iloc[i].split(\" \")\n",
    "    #print(words)\n",
    "    \n",
    "    words = [x.strip() for x in words]\n",
    "    #print(words)\n",
    "    \n",
    "    ind_word_vecs = [w2vec.word_vec(x) for x in words if x in w2vec.vocab]\n",
    "    #print(len(ind_word_vecs), len(ind_word_vecs[0]))\n",
    "    \n",
    "    title_vec[i] = np.array(ind_word_vecs).mean(axis=0)\n",
    "    #print(title_vec[i], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5700, 50)\n"
     ]
    }
   ],
   "source": [
    "#title-vec contains the word2vec representation of all book titles\n",
    "#word2vec representation for a title is obtained by finding the mean of word embedding of each word in the title\n",
    "#title_vec\n",
    "print(title_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4WnrsDtj4IC"
   },
   "outputs": [],
   "source": [
    "# convert any nan values to zeros\n",
    "title_vec = np.nan_to_num(title_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine_similarity  method is to find the similarity among all the titles in the books data\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cosine similarity between each book title with all other book titles\n",
    "\n",
    "cosine_sim_titles = cosine_similarity(title_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 5700)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of cosine_similarity matrix\n",
    "\n",
    "cosine_sim_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.34390155, 0.5948034 , ..., 0.5798488 , 0.57417283,\n",
       "        0.45775519],\n",
       "       [0.34390155, 1.        , 0.25448263, ..., 0.17993782, 0.30491366,\n",
       "        0.31002894],\n",
       "       [0.5948034 , 0.25448263, 1.        , ..., 0.65772461, 0.59280549,\n",
       "        0.45846159],\n",
       "       ...,\n",
       "       [0.5798488 , 0.17993782, 0.65772461, ..., 1.        , 0.46512767,\n",
       "        0.49529352],\n",
       "       [0.57417283, 0.30491366, 0.59280549, ..., 0.46512767, 1.        ,\n",
       "        0.50004542],\n",
       "       [0.45775519, 0.31002894, 0.45846159, ..., 0.49529352, 0.50004542,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity matrix\n",
    "\n",
    "cosine_sim_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oral and maxillofacial surgery an objectivebased textbook e                                                                                                                         \n",
       "1    barrons gre st edition                                                                                                                                                              \n",
       "2    george balanchine the ballet maker eminent lives                                                                                                                                    \n",
       "3    a partner in holiness deepening mindfulness practicing compassion and enriching our lives through the wisdom of r levi yitzhak of berdichevs vol   institute for jewish spirituality\n",
       "4    construction scheduling principles and practices nd edition                                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the first 5 books\n",
    "\n",
    "books_data['title_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most similiar books corresponding to title id 0 - \"Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oral and maxillofacial surgery an objectivebased textbook e'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title.\n",
    "\n",
    "title_id = 0\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0 1351  119   68 1108 1192  249 4645 1625 2430]\n"
     ]
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 0\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "print(top_n_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 0\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most similiar books corresponding to title id 34 - \"Shadowrun: Third Edition (FPR25000)\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shadowrun third edition fpr'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title.\n",
    "\n",
    "title_id = 34\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34, 4879, 4070, 3956, 1857,  274, 5609, 5158, 5098, 3500],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 34\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 34\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most similiar books corresponding to title id 1 - \"Barron's GRE, 21st Edition\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barrons gre st edition'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title.\n",
    "\n",
    "title_id = 1\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 1790, 4755, 3500, 3297, 4127, 5270, 2176,   86, 2284],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 1\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 1\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues with the results obtained using word2vec approach :\n",
    "- if one of the words in the title is present in another word then even if the titles do not matching the tiles are selected as most similar ones because of high cosine similarity\n",
    "- also, most frequently occuring words have more cosine similarity value, though they are not importtant\n",
    "- to overcome this, we use tf-idf weights of each word and then multiply the tf-idf weights with the cosine similarity weights.\n",
    "- With this method we get a weighted cosine similarity between the titles whcich improves the accuracy of recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TF IDF with word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TfidfTransformer directly transforms the word tokens to tf-idf weights without counting them using count-vectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize vectorizer\n",
    "\n",
    "vect = TfidfVectorizer(ngram_range=(1,2),stop_words='english', max_features=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit tf-df transformer and transform the tokens to tf-idf weights\n",
    "\n",
    "vect.fit(books_data['title_clean'])\n",
    "title_matrix = vect.transform(books_data['title_clean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_matrix contains the tfidf weights of all the book titles\n",
    "\n",
    "title_matrix = title_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 5000)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of title_matrix , no of cols = no of features, no of rows = no of titles\n",
    "\n",
    "title_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#title_matrix is very saparse\n",
    "\n",
    "title_matrix[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1290 4110]\n"
     ]
    }
   ],
   "source": [
    "# get tf idf weights for title_id 34\n",
    "\n",
    "idx = 34\n",
    "print(np.where(title_matrix[idx,:] > 0)[0])\n",
    "\n",
    "features = np.where(title_matrix[idx,:] > 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1290 4110]\n"
     ]
    }
   ],
   "source": [
    "# indices of tf-idf weights which have wt greater than 0 for title_id 34\n",
    "\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edition shadowrun\n"
     ]
    }
   ],
   "source": [
    "# words which have wts greater than 0 for title_id 34\n",
    "\n",
    "print(vect.get_feature_names()[1290], vect.get_feature_names()[4110])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['edition', 'shadowrun']\n"
     ]
    }
   ],
   "source": [
    "# get the words which have wts greater than 0 for title_id 34\n",
    "\n",
    "feature_names = [vect.get_feature_names()[x] for x in features]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the tf-idf weights of the 2 words. and check which word has a higher weightage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4337506779996424"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf wt of the word 'edition'.\n",
    "# Though the word edition is frequently occuring it's wt is less\n",
    "\n",
    "title_matrix[34,1290]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.901032934656026"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf wt of the word 'shadowrun'.\n",
    "#Though the word shadow is less frequent,it's wt is more compared to edition, which is more frequent\n",
    "\n",
    "title_matrix[34,4110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "[0.43375068 0.90103293]\n"
     ]
    }
   ],
   "source": [
    "# find the tf-idf weights of all the words in the features\n",
    "\n",
    "print(np.array([title_matrix[idx,x] for x in features]).shape)\n",
    "print(np.array([title_matrix[idx,x] for x in features]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 1)\n",
      "[[0.43375068]\n",
      " [0.90103293]]\n"
     ]
    }
   ],
   "source": [
    "# convert the feature weights matrix into a 2d matrix by adding a column using newaxis\n",
    "feature_weights = np.array([title_matrix[idx,x] for x in features])[:,np.newaxis]\n",
    "print(feature_weights.shape)\n",
    "print(feature_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "[[-7.1063e-01  4.0502e-01 -5.9437e-01 -1.0819e-01  9.8476e-02 -7.5128e-01\n",
      "  -1.2651e+00 -1.3880e+00  5.3070e-01 -2.6628e-01  1.0393e-01  1.0034e-02\n",
      "  -4.0718e-01  5.2769e-02  1.5388e+00 -8.8403e-01 -1.2984e+00 -2.3950e-01\n",
      "  -9.2125e-01  2.4364e-01  6.9175e-01 -8.5089e-01  3.8458e-01  6.3480e-01\n",
      "  -1.0589e-03 -3.8813e-01 -1.7763e+00 -4.4471e-02 -9.1733e-01  1.4402e-01\n",
      "   2.3725e+00 -9.8377e-01 -3.1709e-01  4.9419e-01 -3.3921e-01  3.3320e-01\n",
      "   1.2157e+00  5.1124e-01 -1.0985e+00 -9.3145e-01  1.1839e+00 -8.1248e-01\n",
      "  -6.0077e-01 -8.1775e-01 -6.1546e-01  1.0617e+00  7.2965e-01  4.2010e-03\n",
      "   1.7508e-02 -1.3483e-02]\n",
      " [-9.3703e-01 -1.1261e+00 -5.4092e-01  9.8129e-01 -1.3505e-01 -9.2468e-01\n",
      "   3.2807e-01 -4.0589e-01  7.9908e-01  7.7101e-01 -1.0707e-01  9.5938e-01\n",
      "   1.2107e-01 -6.5970e-01  6.0097e-01 -7.5536e-01 -5.0945e-02  1.9605e-01\n",
      "  -4.8701e-01  7.1163e-01  1.4351e-01 -5.2897e-01  2.6948e-01  3.7200e-02\n",
      "   6.2989e-01  1.3930e+00 -2.8734e-01 -1.2098e-03  8.9359e-01 -8.3085e-01\n",
      "  -4.6550e-01 -1.1742e-01  7.7337e-01  1.2448e-01 -5.8486e-01  8.6144e-01\n",
      "  -2.9045e-01 -1.3011e+00 -1.1179e+00 -5.7811e-01 -1.2770e-01 -9.5794e-01\n",
      "  -6.2872e-01  6.0281e-02 -4.8010e-01 -3.1460e-01  8.8599e-01  8.3970e-01\n",
      "   4.8972e-01  8.4332e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Finding the word2vec vector representations of the words 'edition and 'shadowrun'\n",
    "# if there there is no word2vec representation for a word then add a 50 length vector embedding with zeros\n",
    "# this is done to make the sahape compatiple for multipication with tf-idf weights vector\n",
    "\n",
    "word_vecs = np.array([w2vec.word_vec(x) if x in w2vec.vocab else np.zeros(50) for x in feature_names])\n",
    "print(word_vecs.shape)\n",
    "print(word_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 50)\n",
      "[[-3.08236244e-01  1.75677699e-01 -2.57808394e-01 -4.69274859e-02\n",
      "   4.27140318e-02 -3.25868214e-01 -5.48737984e-01 -6.02045946e-01\n",
      "   2.30191497e-01 -1.15499129e-01  4.50797064e-02  4.35225412e-03\n",
      "  -1.76614606e-01  2.28885902e-02  6.67455544e-01 -3.83448605e-01\n",
      "  -5.63181900e-01 -1.03883288e-01 -3.99592806e-01  1.05679018e-01\n",
      "   3.00047027e-01 -3.69074106e-01  1.66811830e-01  2.75344938e-01\n",
      "  -4.59298606e-04 -1.68351655e-01 -7.70471309e-01 -1.92893261e-02\n",
      "  -3.97892521e-01  6.24687753e-02  1.02907346e+00 -4.26710910e-01\n",
      "  -1.37538005e-01  2.14355251e-01 -1.47132569e-01  1.44525729e-01\n",
      "   5.27310712e-01  2.21750699e-01 -4.76475126e-01 -4.04017073e-01\n",
      "   5.13517427e-01 -3.52413739e-01 -2.60584393e-01 -3.54699607e-01\n",
      "  -2.66956183e-01  4.60513089e-01  3.16486191e-01  1.82218664e-03\n",
      "   7.59410693e-03 -5.84826039e-03]\n",
      " [-8.44294906e-01 -1.01465314e+00 -4.87386752e-01  8.84174593e-01\n",
      "  -1.21684497e-01 -8.33167129e-01  2.95601888e-01 -3.65720247e-01\n",
      "   7.19997410e-01  6.94705386e-01 -9.64735954e-02  8.64432951e-01\n",
      "   1.09088055e-01 -5.94411406e-01  5.41493736e-01 -6.80604244e-01\n",
      "  -4.59031218e-02  1.76647510e-01 -4.38812051e-01  6.41202055e-01\n",
      "   1.29307235e-01 -4.76619394e-01  2.42810346e-01  3.35184253e-02\n",
      "   5.67551657e-01  1.25513888e+00 -2.58902790e-01 -1.09006966e-03\n",
      "   8.05153996e-01 -7.48623218e-01 -4.19430829e-01 -1.05799290e-01\n",
      "   6.96831865e-01  1.12160581e-01 -5.26978146e-01  7.76185814e-01\n",
      "  -2.61705022e-01 -1.17233397e+00 -1.00726473e+00 -5.20896131e-01\n",
      "  -1.15061907e-01 -8.63135474e-01 -5.66497414e-01  5.43151673e-02\n",
      "  -4.32585917e-01 -2.83464953e-01  7.98306191e-01  7.56597340e-01\n",
      "   4.41253837e-01  7.59859065e-02]]\n"
     ]
    }
   ],
   "source": [
    "# multiplying tf idf weights with word2vec\n",
    "\n",
    "res = word_vecs*feature_weights\n",
    "print(res.shape)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50,)\n",
      "[-0.57626558 -0.41948772 -0.37259757  0.41862355 -0.03948523 -0.57951767\n",
      " -0.12656805 -0.4838831   0.47509445  0.28960313 -0.02569694  0.4343926\n",
      " -0.03376328 -0.28576141  0.60447464 -0.53202642 -0.30454251  0.03638211\n",
      " -0.41920243  0.37344054  0.21467713 -0.42284675  0.20481109  0.15443168\n",
      "  0.28354618  0.54339361 -0.51468705 -0.0101897   0.20363074 -0.34307722\n",
      "  0.30482132 -0.2662551   0.27964693  0.16325792 -0.33705536  0.46035577\n",
      "  0.13280285 -0.47529163 -0.74186993 -0.4624566   0.19922776 -0.60777461\n",
      " -0.4135409  -0.15019222 -0.34977105  0.08852407  0.55739619  0.37920976\n",
      "  0.22442397  0.03506882]\n"
     ]
    }
   ],
   "source": [
    "#find mean of the weighted word2vec embeddings\n",
    "\n",
    "res_mean = res.mean(axis=0)\n",
    "print(res_mean.shape)\n",
    "print(res_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get tf-idf weights, word2vec weights , multipy them and get mean of weighted word2vec embedings\n",
    "# get feature_weigths\n",
    "# get word2vec embeddings\n",
    "# multipy feature_weigths with word2vec embeddings\n",
    "# return mean of weighted word2vec embedings\n",
    "\n",
    "def get_weighted_vectors(idx):\n",
    "    \n",
    "    features = np.where(title_matrix[idx,:] > 0)[0]\n",
    "    feature_names = [vect.get_feature_names()[x] for x in features]\n",
    "    feature_weights = np.array([title_matrix[idx,x] for x in features])[:,np.newaxis]\n",
    "    word_vecs = np.array([w2vec.word_vec(x) if x in w2vec.vocab else np.zeros(50) for x in feature_names])\n",
    "    res = word_vecs*feature_weights\n",
    "    return res.mean(axis=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▌                                                                               | 36/5700 [00:00<01:25, 66.57it/s]C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: Mean of empty slice.\n",
      "  \n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5700/5700 [01:17<00:00, 91.20it/s]\n"
     ]
    }
   ],
   "source": [
    "#finding combined tfidf and Word Vector representation of all book titles using w2vec\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "title_vec_weighted = np.zeros((books_data.shape[0],50))\n",
    "\n",
    "for i in tqdm(range(0,books_data.shape[0])):\n",
    "    vec = get_weighted_vectors(i)\n",
    "    \n",
    "    if vec.shape[0] == 0:\n",
    "        title_vec_weighted[i] = np.zeros(50)\n",
    "    else:\n",
    "        title_vec_weighted[i] = vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the weighted vectors obtained by multiplying tf-idf weights with word2vec embeddings, find the top 10 most similiar books to a given book title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 50)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of array of weighted vectors\n",
    "title_vec_weighted.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0407199 ,  0.1032344 , -0.64566988, -0.16534801, -0.32719557,\n",
       "        0.60530042,  0.06560228, -0.09389795,  0.29427193,  0.28394603,\n",
       "        0.1678797 , -0.01078232,  0.1588914 ,  0.18683338,  0.12878867,\n",
       "        0.09225618, -0.65087725, -0.29770656,  0.06181822,  0.38010894,\n",
       "       -0.04204222,  0.23314077,  0.16140571, -0.23818121,  0.03380487,\n",
       "       -0.57586438, -0.22967646, -0.21102348, -0.19878487, -0.161578  ,\n",
       "        1.15137127, -0.17780568, -0.12023563, -0.1977959 ,  0.07819631,\n",
       "        0.27455632,  0.46582114,  0.57829055,  0.3995944 , -0.00779139,\n",
       "       -0.01966397, -0.04205391, -0.1061834 ,  0.66156778,  0.23881343,\n",
       "        0.18094338,  0.52741263,  0.40848348, -0.33696185,  0.19548229])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each weighted vector has 50 embeddings which are weighted\n",
    "title_vec_weighted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-4WnrsDtj4IC"
   },
   "outputs": [],
   "source": [
    "#replace any nan values with zeros\n",
    "\n",
    "title_vec = np.nan_to_num(title_vec_weighted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine_similarity  method is to find the similarity among all the titles in the books data\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consine similarity between each book title with all other book titles\n",
    "\n",
    "cosine_sim_titles = cosine_similarity(title_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5700, 5700)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shape of cosine_similarity matrix\n",
    "\n",
    "cosine_sim_titles.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.21505431,  0.34266771, ...,  0.18887298,\n",
       "         0.45720803,  0.11730321],\n",
       "       [ 0.21505431,  1.        ,  0.12757366, ..., -0.16287118,\n",
       "         0.07269368,  0.15967793],\n",
       "       [ 0.34266771,  0.12757366,  1.        , ...,  0.3067786 ,\n",
       "         0.61461677,  0.16725654],\n",
       "       ...,\n",
       "       [ 0.18887298, -0.16287118,  0.3067786 , ...,  1.        ,\n",
       "         0.32518472,  0.09858321],\n",
       "       [ 0.45720803,  0.07269368,  0.61461677, ...,  0.32518472,\n",
       "         1.        ,  0.33065311],\n",
       "       [ 0.11730321,  0.15967793,  0.16725654, ...,  0.09858321,\n",
       "         0.33065311,  1.        ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosine similarity matrix\n",
    "\n",
    "cosine_sim_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    oral and maxillofacial surgery an objectivebased textbook e                                                                                                                         \n",
       "1    barrons gre st edition                                                                                                                                                              \n",
       "2    george balanchine the ballet maker eminent lives                                                                                                                                    \n",
       "3    a partner in holiness deepening mindfulness practicing compassion and enriching our lives through the wisdom of r levi yitzhak of berdichevs vol   institute for jewish spirituality\n",
       "4    construction scheduling principles and practices nd edition                                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#list the first 5 books\n",
    "\n",
    "books_data['title_clean'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the most similiar books to \"Oral and Maxillofacial Surgery: An Objective-Based Textbook, 2e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'oral and maxillofacial surgery an objectivebased textbook e'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title..\n",
    "\n",
    "title_id = 0\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0, 1108, 1351, 4645,  249, 1192, 1835,  337,  119, 2430],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 0\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 0\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the most similiar books to \"Barron's GRE, 21st Edition\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'barrons gre st edition'"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title..\n",
    "\n",
    "title_id = 1\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1, 4755, 1417, 1790,  168, 5029, 5270, 2284, 5042, 3249],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 1\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 1\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find the most similiar books to \"Shadowrun: Third Edition (FPR25000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'shadowrun third edition fpr'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get books similiar to a given title..\n",
    "\n",
    "title_id = 34\n",
    "books_data['title_clean'].iloc[title_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34, 4879, 2795, 4660, 3956,  274, 4380, 2082, 5167, 3985],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get index of top 10 book titles, which are similar to title_id 34\n",
    "\n",
    "top_n_idx = np.flip(np.argsort(cosine_sim_titles[title_id,]))[0:10]\n",
    "top_n_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34      shadowrun third edition fpr                                                                                                                                                       \n",
       "4879    shadowrun th edition                                                                                                                                                              \n",
       "2795    shadowrun unwired shadowrun catalyst hardcover                                                                                                                                    \n",
       "4660    rigger  a shadowrun sourcebook                                                                                                                                                    \n",
       "3956    minecraft pocket edition the minecraft pocket edition essentials handbook guide to minecraft an unofficial minecraft pocket edition handbook  edition minecraft handbook minecraft\n",
       "274     sixth world almanac shadowrun catalyst hardcover                                                                                                                                  \n",
       "4380    the battletech compendium                                                                                                                                                         \n",
       "2082    street legends shadowrun catalyst hardcover                                                                                                                                       \n",
       "5167    mob war shadowrun fas                                                                                                                                                             \n",
       "3985    battletech handbook house liao a faction sourcebook battletech unnumbered                                                                                                         \n",
       "Name: title_clean, dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matching books fot title_id 34\n",
    "\n",
    "books_data['title_clean'].iloc[top_n_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word2vec embedding weighted by tf-idf weights is giving better results than using only a simple word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "DocumentSimilarityClustering_v1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
